{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/kplr-training/Machine-Learning/blob/main/FR/Supervised/classification/05_Random_Forests__Cancer_Exercice.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "7g2qauQGZInC"
            },
            "source": [
                "## <center> Random Forests </center>\n",
                "- Nous allons utiliser des ensembles qui combinent plusieurs modules d'apprentissage automatique dans un mod\u00e8le plus puissant.\n",
                "Le premier mod\u00e8le \u00e0 explorer est celui des for\u00eats al\u00e9atoires.\n",
                "Nous pouvons consid\u00e9rer une for\u00eat al\u00e9atoire comme une collection d'arbres de d\u00e9cision.\n",
                "<br/><br/>\n",
                "\n",
                "- **Comment les for\u00eats al\u00e9atoires sont-elles meilleures ou diff\u00e9rentes des arbres de d\u00e9cision simples ?**\n",
                "\n",
                "- Nous avons constat\u00e9 que les arbres de d\u00e9cision ont tendance \u00e0 surajuster une partie des donn\u00e9es. La combinaison de plusieurs arbres permet de conserver leur puissance pr\u00e9dictive et peut r\u00e9duire le surajustement en moyennant les r\u00e9sultats.\n",
                "\n",
                "- Une caract\u00e9ristique puissante et distincte des for\u00eats al\u00e9atoires est l'application de la randomisation lors de la construction de chaque arbre. Le principal param\u00e8tre \u00e0 sp\u00e9cifier est le nombre d'estimateurs, qui indique combien d'arbres cr\u00e9er.\n",
                "\n",
                "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true,
                "id": "9aZZD2v5ZInG"
            },
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.datasets import load_breast_cancer\n",
                "\n",
                "cancer = load_breast_cancer()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "NrP3B37ZZInH"
            },
            "source": [
                "#### Cr\u00e9er et tester le mod\u00e8le :\n",
                "1. Diviser les donn\u00e9es.\n",
                "2. Instancier le classifieur de for\u00eat al\u00e9atoire avec les param\u00e8tres par d\u00e9faut."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "0HzIbC4TZInH"
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Fill here\n",
                "\n",
                "# X_train, X_test, y_train, y_test"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "wqvDavJWZInI"
            },
            "source": [
                "#### \u00c9valuons l'algorithme. :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "GfBykIkPZInI"
            },
            "outputs": [],
            "source": [
                "# Fill here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "jDwGPNHZZInJ"
            },
            "source": [
                "* Une pr\u00e9cision de *97*% sur les donn\u00e9es de test avec les param\u00e8tres par d\u00e9faut est plut\u00f4t bonne !\n",
                "Nous pourrions obtenir des r\u00e9sultats potentiellement meilleurs en ajustant d'autres param\u00e8tres tels que :\n",
                "* Le nombre maximal de caract\u00e9ristiques, qui contr\u00f4le la randomisation de chaque arbre.\n",
                "* L'\u00e9lagage pr\u00e9coce, qui est similaire \u00e0 ce qui est fait dans les arbres simples.\n",
                "\n",
                "L'importance des caract\u00e9ristiques est plus repr\u00e9sentative que dans les arbres simples, elle offre une vision plus \u00e9quilibr\u00e9e des poids des caract\u00e9ristiques."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "2ZWwam-kZInJ"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "%matplotlib inline\n",
                "\n",
                "n_features = cancer.data.shape[1]\n",
                "\n",
                "n_features = cancer.data.shape[1]\n",
                "plt.barh(range(n_features), forest.feature_importances_, align='center')\n",
                "plt.yticks(np.arange(n_features), cancer.feature_names)\n",
                "plt.xlabel('Feature Importance')\n",
                "plt.ylabel('Feature')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "S7wO7lvlZInJ"
            },
            "source": [
                "- Dans les arbres simples, nous avons constat\u00e9 que la caract\u00e9ristique \"worst radius\" avait un poids significativement plus \u00e9lev\u00e9 par rapport aux autres caract\u00e9ristiques, qui \u00e9taient de 30.\n",
                "\n",
                "- Avec les for\u00eats al\u00e9atoires, nous pouvons voir que de nombreuses autres caract\u00e9ristiques ont une contribution non nulle, elles jouent un r\u00f4le plus important dans la prise de d\u00e9cision par rapport \u00e0 l'arbre de d\u00e9cision unique. Les for\u00eats al\u00e9atoires, dans notre cas, semblent offrir un choix plus \u00e9clair\u00e9."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "NswaJSLqZInK"
            },
            "source": [
                "### Avantages potentiels des for\u00eats al\u00e9atoires\n",
                "\n",
                " - Puissants et largement utilis\u00e9s.\n",
                " - Performent bien avec les param\u00e8tres par d\u00e9faut.\n",
                " - Ne n\u00e9cessitent pas de mise \u00e0 l'\u00e9chelle des donn\u00e9es.\n",
                " - La randomisation les rend meilleurs que les arbres de d\u00e9cision simples.\n",
                "\n",
                "### Param\u00e8tres \u00e0 r\u00e9gler\n",
                "\n",
                " - n_jobs : Nombre de c\u0153urs \u00e0 utiliser pour l'entra\u00eenement (n_jobs=-1, pour tous les c\u0153urs). Utiliser deux c\u0153urs doublera la vitesse par rapport \u00e0 l'utilisation d'un seul c\u0153ur.\n",
                " - n_estimators : Nombre d'arbres \u00e0 utiliser. Plus il y en a, mieux c'est, cela r\u00e9duit le surajustement, MAIS il faut prendre en compte le temps d'entra\u00eenement et l'allocation de m\u00e9moire. Plus il y a d'arbres, plus les ressources de l'ordinateur sont sollicit\u00e9es.\n",
                " - max_depth, pour l'\u00e9lagage pr\u00e9coce.\n",
                " - max_features, pour la randomisation. Les valeurs par d\u00e9faut sont :\n",
                "     - max_features = sqrt(n_features), pour la classification.\n",
                "     - max_features = log2(n_features), pour la r\u00e9gression.\n",
                " - etc.\n",
                "\n",
                "### Inconv\u00e9nients potentiels des for\u00eats al\u00e9atoires\n",
                "\n",
                "- Performance moins bonne sur des donn\u00e9es tr\u00e8s dimensionnelles et \u00e9parses (donn\u00e9es textuelles).\n",
                "- Les grands ensembles de donn\u00e9es n\u00e9cessitent plus de ressources pour l'entra\u00eenement (temps, processeurs, etc.).\n",
                "- Ne peuvent pas \u00eatre visualis\u00e9es aussi facilement qu'un seul arbre de d\u00e9cision."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}